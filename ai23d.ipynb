{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from keras.utils import np_utils\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "\n",
    "names = [item[20:-1] for item in sorted(glob(\"images/bones/train/*/\"))]\n",
    "train_files, train_targets = load_dataset('images/bones/train')\n",
    "valid_files, valid_targets = load_dataset('images/bones/valid')\n",
    "test_files, test_targets = load_dataset('images/bones/test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/256 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 17/256 [00:00<00:01, 144.23it/s]\u001b[A\n",
      " 12%|█▏        | 30/256 [00:00<00:01, 127.64it/s]\u001b[A\n",
      " 17%|█▋        | 43/256 [00:00<00:01, 125.43it/s]\u001b[A\n",
      " 21%|██        | 54/256 [00:00<00:01, 119.15it/s]\u001b[A\n",
      " 28%|██▊       | 72/256 [00:00<00:01, 117.33it/s]\u001b[A\n",
      " 33%|███▎      | 85/256 [00:00<00:01, 117.20it/s]\u001b[A\n",
      " 39%|███▊      | 99/256 [00:00<00:01, 122.55it/s]\u001b[A\n",
      " 49%|████▉     | 125/256 [00:00<00:00, 145.36it/s]\u001b[A\n",
      " 62%|██████▏   | 159/256 [00:01<00:00, 173.98it/s]\u001b[A\n",
      " 71%|███████   | 181/256 [00:01<00:00, 183.88it/s]\u001b[A\n",
      " 79%|███████▉  | 202/256 [00:01<00:00, 161.63it/s]\u001b[A\n",
      " 86%|████████▋ | 221/256 [00:01<00:00, 92.46it/s] \u001b[A\n",
      " 92%|█████████▏| 236/256 [00:01<00:00, 93.88it/s]\u001b[A\n",
      " 98%|█████████▊| 251/256 [00:02<00:00, 92.89it/s]\u001b[A\n",
      "100%|██████████| 256/256 [00:02<00:00, 121.43it/s]\u001b[A\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      " 71%|███████   | 17/24 [00:00<00:00, 168.36it/s]\u001b[A\n",
      "100%|██████████| 24/24 [00:00<00:00, 164.74it/s]\u001b[A\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|████████▎ | 20/24 [00:00<00:00, 191.93it/s]\u001b[A\n",
      "100%|██████████| 24/24 [00:00<00:00, 189.19it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 224, 224, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 112, 112, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 133)               6673541   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 133)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 133)               17822     \n",
      "=================================================================\n",
      "Total params: 6,701,907.0\n",
      "Trainable params: 6,701,907.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(133, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples, validate on 24 samples\n",
      "Epoch 1/10\n",
      "240/256 [===========================>..] - ETA: 0s - loss: 0.8492 - acc: 0.6542Epoch 00000: val_loss improved from inf to 1.15795, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "256/256 [==============================] - 9s - loss: 0.8856 - acc: 0.6406 - val_loss: 1.1579 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "240/256 [===========================>..] - ETA: 0s - loss: 0.8548 - acc: 0.6292Epoch 00001: val_loss did not improve\n",
      "256/256 [==============================] - 9s - loss: 0.8548 - acc: 0.6250 - val_loss: 1.2974 - val_acc: 0.5417\n",
      "Epoch 3/10\n",
      "240/256 [===========================>..] - ETA: 0s - loss: 0.7949 - acc: 0.6917Epoch 00002: val_loss did not improve\n",
      "256/256 [==============================] - 9s - loss: 0.7906 - acc: 0.6836 - val_loss: 1.5797 - val_acc: 0.4583\n",
      "Epoch 4/10\n",
      "240/256 [===========================>..] - ETA: 0s - loss: 0.5595 - acc: 0.7458Epoch 00003: val_loss did not improve\n",
      "256/256 [==============================] - 9s - loss: 0.5515 - acc: 0.7578 - val_loss: 1.5206 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "240/256 [===========================>..] - ETA: 0s - loss: 0.4898 - acc: 0.7958Epoch 00004: val_loss did not improve\n",
      "256/256 [==============================] - 9s - loss: 0.4858 - acc: 0.7969 - val_loss: 1.9141 - val_acc: 0.4583\n",
      "Epoch 6/10\n",
      "240/256 [===========================>..] - ETA: 0s - loss: 0.4650 - acc: 0.8333Epoch 00005: val_loss did not improve\n",
      "256/256 [==============================] - 9s - loss: 0.4795 - acc: 0.8281 - val_loss: 1.6282 - val_acc: 0.5417\n",
      "Epoch 7/10\n",
      "240/256 [===========================>..] - ETA: 0s - loss: 0.4175 - acc: 0.8375Epoch 00006: val_loss did not improve\n",
      "256/256 [==============================] - 9s - loss: 0.4138 - acc: 0.8359 - val_loss: 1.6320 - val_acc: 0.6250\n",
      "Epoch 8/10\n",
      "240/256 [===========================>..] - ETA: 0s - loss: 0.3220 - acc: 0.8792Epoch 00007: val_loss did not improve\n",
      "256/256 [==============================] - 9s - loss: 0.4491 - acc: 0.8438 - val_loss: 1.3180 - val_acc: 0.4583\n",
      "Epoch 9/10\n",
      "240/256 [===========================>..] - ETA: 0s - loss: 0.3222 - acc: 0.8750Epoch 00008: val_loss did not improve\n",
      "256/256 [==============================] - 9s - loss: 0.3191 - acc: 0.8750 - val_loss: 1.4811 - val_acc: 0.5833\n",
      "Epoch 10/10\n",
      "240/256 [===========================>..] - ETA: 0s - loss: 0.1963 - acc: 0.9500Epoch 00009: val_loss did not improve\n",
      "256/256 [==============================] - 9s - loss: 0.1933 - acc: 0.9453 - val_loss: 1.8311 - val_acc: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2f06447b8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bones test accuracy: 70.8333%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')\n",
    "\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Bones test accuracy: %.4f%%' % test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prediction Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def prediction_machine(img_path):\n",
    "    prediction = np.argmax(model.predict(np.expand_dims(tensor, axis=0)))\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bone Disease Diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "    import cv2\n",
    "\n",
    "    final_images = np.array(glob('images/final/*'))\n",
    "\n",
    "    for img_path in final_images:\n",
    "        p_img = cv2.imread(img_path)\n",
    "        plt.imshow(p_img)\n",
    "        plt.show()\n",
    "        prediction = prediction_machine(img_path)\n",
    "        print('Predicted Disease: {0}'.format(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
